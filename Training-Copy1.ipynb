{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "# Imports for this repository\n",
    "from gmm_data_generator import load_db\n",
    "from numpy_dataset import NumpyDataset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from random import choices\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {'batch_size': 512,\n",
    "          'zdim': 2,\n",
    "          'gamma':0.5,\n",
    "          'beta1':0.5,\n",
    "          'beta2':0.999,\n",
    "          'epochs':20,\n",
    "          'lr_d': 15e-5,\n",
    "          'lr_g': 15e-4,\n",
    "          'epsilon': 1e-8,  # for avoiding numerical instabilities\n",
    "          'samp_num_gen': 2500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = load_db()\n",
    "train_dataset = NumpyDataset(training_data)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=PARAMS['batch_size'],\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(training_data[:, 0], training_data[:, 1], 'o',label='real data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(PARAMS['zdim'], 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, 2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 2)\n",
    "        return img\n",
    "\n",
    "    def save(self, name):\n",
    "        torch.save(self.model.state_dict(), name)\n",
    "\n",
    "    def load(self):\n",
    "        self.model.load_state_dict(torch.load(\"./checkpoints/generator_0\"))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity\n",
    "\n",
    "    def save(self, name):\n",
    "        torch.save(self.model.state_dict(), name)\n",
    "\n",
    "    def load(self):\n",
    "        self.model.load_state_dict(torch.load(\"./checkpoints/discriminator_0\"))\n",
    "\n",
    "\n",
    "def sample_from_distribution(distribution):\n",
    "    return Categorical(distribution).sample(sample_shape=torch.Size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "fixed_z = Tensor(np.random.normal(0, 1, (512, PARAMS['zdim']))).cuda()\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()\n",
    "adversarial_loss = torch.nn.BCELoss().cuda()\n",
    "for iter in range(1000):\n",
    "    for data in train_loader:\n",
    "        Tensor = torch.FloatTensor\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        valid = Tensor(data.size(0), 1).fill_(1.0).requires_grad_(False).to(device)\n",
    "        optimizer_G = torch.optim.Adam(generator.parameters(), lr=PARAMS['lr_g'], betas=(PARAMS['beta1'], PARAMS['beta2']))\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        z = Tensor(np.random.normal(0, 1, (data.shape[0], PARAMS['zdim']))).to(device)\n",
    "        gen_imgs = generator(z).to(device)\n",
    "        d_res = discriminator(gen_imgs).to(device)\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(d_res, valid).to(device)  # * discriminator_distribution[d_index]\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        optimizer_TD = torch.optim.Adam(discriminator.parameters(), lr=PARAMS['lr_g'], betas=(PARAMS['beta1'], PARAMS['beta2']))\n",
    "    \n",
    "        valid = Tensor(data.size(0), 1).fill_(1.0).requires_grad_(False).to(device)\n",
    "        fake = Tensor(data.size(0), 1).fill_(0.0).requires_grad_(False).to(device)\n",
    "\n",
    "        real_imgs = data.clone().detach().to(device)\n",
    "\n",
    "        optimizer_TD.zero_grad()\n",
    "        gen_imgs = generator(z).to(device)\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs).to(device), valid)\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()).to(device), fake) \n",
    "        d_loss = (real_loss + fake_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_TD.step()\n",
    "        \n",
    "        if iter % 100==0:\n",
    "            g_gen_img = generator(fixed_z).cpu().detach().numpy()\n",
    "            plt.plot(data[:, 0], data[:, 1], 'o',label='real data')\n",
    "            plt.plot(g_gen_img[:, 0], g_gen_img[:, 1], 'o',label='real data')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_oracle(data, generator, discriminator, d_dist, discriminator_list, epoch):\n",
    "    Tensor = torch.FloatTensor\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    valid = Tensor(data.size(0), 1).fill_(1.0).requires_grad_(False).to(device)\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=PARAMS['lr_g'], betas=(PARAMS['beta1'], PARAMS['beta2']))\n",
    "    \n",
    "    for d_index in range(len(d_dist)):\n",
    "#         if epoch > 2 and epoch % 3 == d_index:\n",
    "#             continue\n",
    "        if d_dist[d_index] == 0:\n",
    "            continue\n",
    "        z = Tensor(np.random.normal(0, 1, (data.shape[0], PARAMS['zdim']))).to(device)\n",
    "        gen_imgs = generator(z).to(device)\n",
    "        optimizer_G.zero_grad()\n",
    "        D = discriminator_list[d_index].cuda()\n",
    "        unrolled_steps = 5\n",
    "        if unrolled_steps > 0:\n",
    "            torch.save(D.model.state_dict(), \"backup.pth\")\n",
    "            for i in range(unrolled_steps):\n",
    "                discriminator_unrolled(generator, D, data, z)\n",
    "        d_res = D(gen_imgs).to(device)\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(d_res, valid).to(device)  *0.5 * d_dist[d_index] \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        if unrolled_steps > 0:\n",
    "            D.model.load_state_dict(torch.load(\"backup.pth\"))\n",
    "                                                                     \n",
    "    optimizer_G.zero_grad()\n",
    "    z = Tensor(np.random.normal(0, 1, (data.shape[0], PARAMS['zdim']))).to(device)\n",
    "    gen_imgs = generator(z).to(device)\n",
    "    unrolled_steps = 5\n",
    "    if unrolled_steps > 0:\n",
    "        torch.save(discriminator.model.state_dict(), \"backup.pth\")\n",
    "        for i in range(unrolled_steps):\n",
    "            discriminator_unrolled(generator, discriminator, data, z)\n",
    "    d_res = discriminator(gen_imgs).to(device) \n",
    "    # Loss measures generator's ability to fool the discriminator\n",
    "    g_loss = adversarial_loss(d_res, valid).to(device) * 0.5  # * discriminator_distribution[d_index]\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    if unrolled_steps > 0:\n",
    "        discriminator.model.load_state_dict(torch.load(\"backup.pth\"))\n",
    "    return generator\n",
    "\n",
    "def discriminator_oracle(data, generator, discriminator, g_dist, generator_list, epoch):\n",
    "    Tensor = torch.FloatTensor\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer_TD = torch.optim.Adam(discriminator.parameters(), lr=PARAMS['lr_g'], betas=(PARAMS['beta1'], PARAMS['beta2']))\n",
    "    \n",
    "    valid = Tensor(data.size(0), 1).fill_(1.0).requires_grad_(False).to(device)\n",
    "    fake = Tensor(data.size(0), 1).fill_(0.0).requires_grad_(False).to(device)\n",
    "    \n",
    "    real_imgs = data.clone().detach().to(device)\n",
    "    \n",
    "    optimizer_TD.zero_grad()\n",
    "    for g in range(len(g_dist)):\n",
    "#         if epoch > 2 and g == epoch % 3:\n",
    "#             continue\n",
    "        if g_dist[g] == 0:\n",
    "            continue\n",
    "        G = generator_list[g].cuda()\n",
    "        z = Tensor(np.random.normal(0, 1, (data.shape[0], PARAMS['zdim']))).to(device)\n",
    "        gen_imgs = G(z).to(device)\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs).to(device), valid)\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()).to(device), fake) \n",
    "        d_loss = (real_loss + fake_loss) * g_dist[g] * 0.5\n",
    "        d_loss.backward()\n",
    "        optimizer_TD.step()\n",
    "    \n",
    "    z = Tensor(np.random.normal(0, 1, (data.shape[0], PARAMS['zdim']))).to(device)\n",
    "    gen_imgs = generator(z).to(device)\n",
    "    real_loss = adversarial_loss(discriminator(real_imgs).to(device), valid)\n",
    "    # Measure discriminator's ability to classify real from generated samples\n",
    "    fake_loss = adversarial_loss(discriminator(gen_imgs.detach()).to(device), fake) \n",
    "    d_loss = (real_loss + fake_loss) * 0.5\n",
    "    d_loss.backward()\n",
    "    optimizer_TD.step()\n",
    "    return discriminator\n",
    "\n",
    "def discriminator_unrolled(generator, discriminator, imgs, d_gen_input=None):\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=PARAMS['lr_d'], betas=(PARAMS['beta1'], PARAMS['beta2']))\n",
    "    # Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    Tensor = torch.FloatTensor\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    optimizer_D.zero_grad()\n",
    "    real_imgs = imgs.clone().detach().to(device)\n",
    "    valid = Tensor(imgs.size(0), 1).fill_(1.0).requires_grad_(False).to(device)\n",
    "    fake = Tensor(imgs.size(0), 1).fill_(0.0).requires_grad_(False).to(device)\n",
    "\n",
    "    # Measure discriminator's ability to classify real from generated samples\n",
    "    real_loss = adversarial_loss(discriminator(real_imgs).to(device), valid)\n",
    "    if d_gen_input is None:\n",
    "        # Sample noise as generator input\n",
    "        d_gen_input = Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))).to(device)\n",
    "        # Generate a batch of images\n",
    "    gen_imgs = generator(d_gen_input).to(device)\n",
    "    fake_loss = adversarial_loss(discriminator(gen_imgs.detach()).to(device), fake)\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.BCELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_payoff(G,D):\n",
    "    Tensor = torch.FloatTensor\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "    for i in train_loader:\n",
    "        valid = Tensor(PARAMS['batch_size'], 1).fill_(1.0).requires_grad_(False).to(device)\n",
    "        fake = Tensor(PARAMS['batch_size'], 1).fill_(0.0).requires_grad_(False).to(device)\n",
    "\n",
    "        real_imgs = i.clone().detach().to(device)\n",
    "        \n",
    "        \n",
    "        z = Tensor(np.random.normal(0, 1, (PARAMS['batch_size'], PARAMS['zdim']))).to(device)\n",
    "        gen_imgs = G(z).to(device)\n",
    "        \n",
    "        real_loss = adversarial_loss(D(real_imgs).to(device), valid)\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        fake_loss = adversarial_loss(D(gen_imgs.detach()).to(device), fake) \n",
    "        d_loss = (real_loss + fake_loss).detach().cpu().clone()\n",
    "        \n",
    "        g_loss = adversarial_loss(D(gen_imgs.detach()).to(device), valid).detach().cpu().clone()\n",
    "        break\n",
    "    return -g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()\n",
    "calculate_payoff(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_calculate_missing_entries(meta_matrix, generator_list, discriminator_list):\n",
    "    meta_matrix = np.zeros((len(generator_list), len(discriminator_list)))\n",
    "    for i in range(len(generator_list)):\n",
    "        for j in range(len(discriminator_list)):\n",
    "            meta_matrix[i][j] = calculate_payoff(generator_list[i], discriminator_list[j])\n",
    "    return meta_matrix\n",
    "#     if len(generator_list)==1 and len(discriminator_list)==1:\n",
    "#         meta_matrix[0][0] = calculate_payoff(generator_list[0], discriminator_list[0])\n",
    "#     else:\n",
    "#         num_generator = len(generator_list)-1\n",
    "#         aug_col = np.zeros((num_generator, 1))\n",
    "#         for gen in range(num_generator):\n",
    "#             g = generator_list[gen].cuda()\n",
    "#             aug_col[gen] = calculate_payoff(g, discriminator_list[-1])\n",
    "#         meta_matrix = np.column_stack((meta_matrix, aug_col))\n",
    "        \n",
    "#         num_discriminator = len(discriminator_list)\n",
    "#         aug_row = np.zeros((num_discriminator, 1))\n",
    "#         for dis in range(num_discriminator):\n",
    "#             discriminator = discriminator_list[dis].cuda()\n",
    "#         aug_row[dis] = calculate_payoff(generator_list[-1], discriminator).detach().cpu().clone()\n",
    "#         aug_row = aug_row.transpose()\n",
    "#         meta_matrix = np.row_stack((meta_matrix, aug_row))\n",
    "#     return meta_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add, neg\n",
    "def NE_solver(payoff_matrix, iterations=100):\n",
    "    'Return the oddments (mixed strategy ratios) for a given payoff matrix'\n",
    "    transpose = list(zip(*payoff_matrix))\n",
    "    numrows = len(payoff_matrix)\n",
    "    numcols = len(transpose)\n",
    "    row_cum_payoff = [0] * numrows\n",
    "    col_cum_payoff = [0] * numcols\n",
    "    colpos = list(range(numcols))\n",
    "    rowpos = list(map(neg, range(numrows)))\n",
    "    colcnt = [0] * numcols\n",
    "    rowcnt = [0] * numrows\n",
    "    active = 0\n",
    "    for i in range(iterations):\n",
    "        rowcnt[active] += 1\n",
    "        col_cum_payoff = list(map(add, payoff_matrix[active], col_cum_payoff))\n",
    "        active = min(list(zip(col_cum_payoff, colpos)))[1]\n",
    "        colcnt[active] += 1\n",
    "        row_cum_payoff = list(map(add, transpose[active], row_cum_payoff))\n",
    "        active = -max(list(zip(row_cum_payoff, rowpos)))[1]\n",
    "    value_of_game = (max(row_cum_payoff) + min(col_cum_payoff)) / 2.0 / iterations\n",
    "    return np.array([i/100 for i in rowcnt], dtype=float), np.array([i/100 for i in colcnt], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "g_samples = []\n",
    "Tensor = torch.FloatTensor\n",
    "fixed_z = Tensor(np.random.normal(0, 1, (512, PARAMS['zdim']))).cuda()\n",
    "generator_list = []\n",
    "discriminator_list = []\n",
    "generator_list.append(Generator())\n",
    "discriminator_list.append(Discriminator())\n",
    "g_dist = []\n",
    "d_dist = []\n",
    "global dataset\n",
    "for d in train_loader:\n",
    "    dataset = d\n",
    "    break\n",
    "g_samples.append(generator_list[0].cuda()(fixed_z).cpu().detach().numpy())\n",
    "for iter in range(100):\n",
    "    for d in train_loader:\n",
    "        generator_list[0] = generator_oracle(d, generator_list[0].cuda(), discriminator_list[0].cuda(), d_dist, discriminator_list, 3)\n",
    "        discriminator_list[0] = discriminator_oracle(d, generator_list[0].cuda(), discriminator_list[0].cuda(), g_dist, generator_list, 3)\n",
    "g_dist = [1]\n",
    "d_dist = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_matrix = np.zeros((1,1))\n",
    "meta_matrix = augment_calculate_missing_entries(meta_matrix, generator_list, discriminator_list)\n",
    "# Start Training Loop\n",
    "for epoch in tqdm(range(100)): #PARAMS['epochs'])):\n",
    "#     if epoch > 2:\n",
    "#         G = generator_list[epoch %3]\n",
    "#         D = discriminator_list[epoch%3]\n",
    "#     else:\n",
    "    G = Generator()\n",
    "    D = Discriminator()\n",
    "    if cuda:\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "#         generator_list.append(G)\n",
    "        \n",
    "#     G = generator_list[0].cuda()\n",
    "#     D = discriminator_list[0].cuda()\n",
    "    \n",
    "#     D = discriminator_list[0]\n",
    "    for iter in range(200):\n",
    "        for d in train_loader:\n",
    "            D = discriminator_oracle(d, G, D, g_dist, generator_list, epoch)\n",
    "    for iter in range(200):\n",
    "        for d in train_loader:\n",
    "            G = generator_oracle(d, G, D, d_dist, discriminator_list, epoch)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if epoch ==2:\n",
    "#         generator_list[0] = G\n",
    "#     elif epoch > 2:\n",
    "#         generator_list[epoch % 3] = G\n",
    "#     else:\n",
    "    generator_list.append(G)\n",
    "#     discriminator_list[0] = D\n",
    "#     if epoch ==2:\n",
    "#         discriminator_list[0] = D\n",
    "#     elif epoch > 2:\n",
    "#         discriminator_list[epoch % 3] = D\n",
    "#     else:\n",
    "    discriminator_list.append(D)\n",
    "    meta_matrix = augment_calculate_missing_entries(meta_matrix, generator_list, discriminator_list)\n",
    "    g_dist, d_dist = NE_solver(meta_matrix)\n",
    "    print(g_dist)\n",
    "    g_sample = []\n",
    "    population = np.arange(0,len(generator_list))\n",
    "    weights = g_dist\n",
    "#     for i in range(len(generator_list)):\n",
    "#         weights.append(1/len(generator_list))\n",
    "    for g in generator_list:\n",
    "        g_sample.append(g(fixed_z).cpu().detach().numpy())\n",
    "    g_gen_img = np.ndarray((512,2))\n",
    "    for i in range(512):\n",
    "        index = choices(population, weights)\n",
    "        g_gen_img[i] = g_sample[index[0]][i]\n",
    "    plt.plot(dataset[:, 0], dataset[:, 1], 'o',label='real data')\n",
    "    \n",
    "#     plt.plot(g_sample[epoch % 3][:, 0], g_sample[epoch % 3][:, 1], 'o',label='real data')\n",
    "#     plt.plot(g_sample[1][:, 0], g_sample[1][:, 1], 'o',label='real data')\n",
    "#     if epoch >2:\n",
    "#         plt.plot(g_sample[2][:, 0], g_sample[2][:, 1], 'o',label='real data')\n",
    "    plt.plot(g_gen_img[:, 0], g_gen_img[:, 1], 'o', label='real data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "np_samples_ = g_samples\n",
    "cols = len(np_samples_)\n",
    "bg_color  = sns.color_palette('Greens', n_colors=256)[0]\n",
    "plt.figure(figsize=(2*5, 2*(cols/5)+1))\n",
    "for i, samps in enumerate(np_samples_):\n",
    "    if i==0:\n",
    "        ax = plt.subplot((cols/5)+1.5,5,1)  \n",
    "        plt.ylabel('DO-GAN')  \n",
    "    else:\n",
    "        plt.subplot((cols/5)+1.5,5,i+1, sharex=ax, sharey=ax)\n",
    "    ax2 = sns.kdeplot(samps[:, 0], samps[:, 1], shade=True, cmap='Greens', n_levels=30, clip=[[-3,3]]*2)\n",
    "    ax2.set_facecolor(bg_color)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.title('iteration %d'%(i*1000))\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "G.cuda()\n",
    "Tensor = torch.FloatTensor\n",
    "z = Tensor(np.random.normal(0, 1, (512, PARAMS['zdim']))).cuda()\n",
    "g_samples1 = G(z).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_samples1[:, 0], g_samples1[:, 1], 'o',label='real data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_samples1[0:300, 0], g_samples1[0:300, 1], 'o',label='real data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples= []\n",
    "g_samples.append(g_samples1[0:300,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "G.cuda()\n",
    "Tensor = torch.FloatTensor\n",
    "z = Tensor(np.random.normal(0, 1, (512, PARAMS['zdim']))).cuda()\n",
    "g_samples2 = G(z).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_samples2[:, 0], g_samples2[:, 1], 'o',label='real data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_samples2[301:512, 0], g_samples2[301:512, 1], 'o',label='real data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples.append(g_samples2[301:512, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples = np.concatenate((, b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_samples[:, 0], g_samples[:, 1], 'o',label='real data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples = np.ndarray((512,2))\n",
    "for i in range(512):\n",
    "    if i < 300:\n",
    "        g_samples[i] = g_samples1[i]\n",
    "    else:\n",
    "        g_samples[i] = g_samples2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(g_samples1[:, 0], g_samples1[:, 1], 'x',label='real data')\n",
    "plt.plot(g_samples2[:, 0], g_samples2[:, 1], 'x',label='real data')\n",
    "plt.plot(g_samples[:, 0], g_samples[:, 1], 'o',label='real data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(g_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples1 = G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(g_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_samples1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.from_numpy(g_samples).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk =torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
